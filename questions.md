[Q1] You have a transformers model finetuned for a particular task, say sentiment analysis. During evaluation, how much does the prediction change by choosing different
  windows of text within the sentence to make the prediction? Does it relate to the uncertainity of the model?
